{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n",
    "\n",
    "from config import db_password\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add the clean movie function that takes in the argument, \"movie\".\n",
    "#\n",
    "# This function is part of the execute step of the three-step process of data cleaning:\n",
    "# .inspect / .plan / .execute\n",
    "# The .inspect and .plan steps having been finished throughout Module 8, this notebook consists of\n",
    "# primarily summation .execute steps; a descriptive walk-through of the full process is found in\n",
    "# the Jupyter notebook file \"ETL_StepThree.ipynb,\" in the repository, or of course in the online\n",
    "# material for Module 8. Running this function on the (full) set of movies in the current Wikipedia\n",
    "# file dataset pares what were 193 initial columns to 39 (which have been filtered and merged --\n",
    "# as printed in commented-out line 39 of the `extract_transform_load()` function below in this\n",
    "# notebook -- that line is as follows: `print(len(wiki_movies_df.columns))`)\n",
    "# ... and the list of the 39 columns is:\n",
    "# ['url', 'year', 'imdb_link', 'title', 'Based on', 'Starring', 'Narrated by', 'Cinematography',\n",
    "# 'Release date', 'Running time', 'Country', 'Language', 'Budget', 'Box office', 'Director',\n",
    "# 'Distributor', 'Editor(s)', 'Composer(s)', 'Producer(s)', 'Production company(s)', 'Writer(s)',\n",
    "# 'Genre', 'Original language(s)', 'Original network', 'Executive producer(s)',\n",
    "# 'Production location(s)', 'Picture format', 'Audio format', 'Voices of', 'Followed by',\n",
    "# 'Created by', 'Preceded by', 'Suggested by', 'alt_titles', 'Recorded', 'Venue', 'Label',\n",
    "# 'Color process', 'Animator(s)'].\n",
    "#\n",
    "# Below is a list of the initial 193 columns (found from D1 `ETL_function_test.ipynb` Step 4\n",
    "# DataFrame, or commented-out line 34 [which is: `wiki_movies_df = pd.DataFrame(wiki_movies_raw)`]\n",
    "# of the `extract_transform_load()` function below in *this* notebook) ...\n",
    "# ['url', 'year', 'imdb_link', 'title', 'Directed by', 'Produced by', 'Screenplay by',\n",
    "# 'Story by', 'Based on', 'Starring', 'Narrated by', 'Music by', 'Cinematography', 'Edited by',\n",
    "# 'Productioncompany ', 'Distributed by', 'Release date', 'Running time', 'Country', 'Language',\n",
    "# 'Budget', 'Box office', 'Written by', 'Genre', 'Theme music composer', 'Country of origin',\n",
    "# 'Original language(s)', 'Producer(s)', 'Editor(s)', 'Production company(s)', 'Original network',\n",
    "# 'Original release', 'Productioncompanies ', 'Executive producer(s)', 'Production location(s)',\n",
    "# 'Distributor', 'Picture format', 'Audio format', 'Voices of', 'Followed by', 'Composer(s)',\n",
    "# 'Created by', 'Also known as', 'Opening theme', 'No. of episodes', 'Preceded by', 'Author',\n",
    "# 'Publisher', 'Publication date', 'Media type', 'Pages', 'ISBN', 'OCLC', 'LC Class',\n",
    "# 'Cover artist', 'Series', 'Set in', 'Adaptation by', 'Suggested by', 'Biographical data',\n",
    "# 'Born', 'Died', 'Resting place', 'Occupation', 'Years active', 'Spouse(s)', 'Children',\n",
    "# 'Parent(s)', 'Genres', 'Instruments', 'Labels', 'Website', 'Traditional', 'Mandarin', 'Type',\n",
    "# 'Industry', 'Fate', 'Founded', 'Founder', 'Headquarters', 'Parent', 'Released', 'Recorded',\n",
    "# 'Venue', 'Length', 'Label', 'Director', 'Producer', 'Area', 'Coordinates', 'Status',\n",
    "# 'Opening date', 'Closing date', 'Replaced', 'Replaced by', 'Name', 'Attraction type', 'Music',\n",
    "# 'Duration', 'Simplified Chinese', 'Traditional Chinese', 'Hanyu Pinyin', 'Literal meaning',\n",
    "# 'Transcriptions', 'Bopomofo', 'Gwoyeu Romatzyh', 'Wade–Giles', 'IPA', 'Yale Romanization',\n",
    "# 'Jyutping', 'Hokkien POJ', 'Animation by', 'Color process', 'Engine(s)', 'Genre(s)',\n",
    "# 'Actor control', 'Production company', 'Release(s)', 'Format(s)', 'Simplified', 'Characters',\n",
    "# 'Date premiered', 'Place premiered', 'Setting', 'Original language', 'Subject', 'Published',\n",
    "# 'Dewey Decimal', 'Text', 'Illustrator', 'Original title', 'Published in English', 'French',\n",
    "# 'Developed by', 'Ending theme', 'No. of seasons', 'Nationality', 'Portrayed by', 'Alias',\n",
    "# 'Species', 'Gender', 'Family', 'Alma mater', 'Camera setup', 'Novel(s)', 'Comics', 'Film(s)',\n",
    "# 'Screen story by', 'Hangul', 'Revised Romanization', 'McCune–Reischauer', 'Developer(s)',\n",
    "# 'Publisher(s)', 'Designer(s)', 'Programmer(s)', 'Artist(s)', 'Writer(s)', 'Engine',\n",
    "# 'Platform(s)', 'Release', 'Mode(s)', 'Original work', 'Television series', 'Japanese',\n",
    "# 'Hepburn', 'Literally', 'Cantonese', 'Full name', 'Height', 'Seasons', 'Chinese',\n",
    "# 'Other names', 'Relatives', 'Yiddish', 'Formerly', 'Key people', 'Total assets', 'Owner', \n",
    "# 'Number of employees', 'Divisions', 'Subsidiaries', 'Arabic', 'Romanized', 'Predecessor',\n",
    "# 'Founders', 'Area served', 'Products', 'Services', 'Russian', 'Hebrew', 'Revenue',\n",
    "# 'Operating income', 'Polish']\n",
    "\n",
    "def clean_movie(movie):\n",
    "    movie = dict(movie) #create a non-destructive copy\n",
    "    # make an empty dict to hold all of the alternative titles...\n",
    "    alt_titles = {}\n",
    "    # combine alternate titles into one list\n",
    "    for key in ['Also known as',\n",
    "                'Arabic',\n",
    "                'Cantonese',\n",
    "                'Chinese',\n",
    "                'French',\n",
    "                'Hangul',\n",
    "                'Hebrew',\n",
    "                'Hepburn',\n",
    "                'Japanese',\n",
    "                'Literally',\n",
    "                'Mandarin',\n",
    "                'McCune–Reischauer',\n",
    "                'Original title',\n",
    "                'Polish',\n",
    "                'Revised Romanization',\n",
    "                'Romanized',\n",
    "                'Russian',\n",
    "                'Simplified',\n",
    "                'Traditional',\n",
    "                'Yiddish'\\\n",
    "                #'title'\n",
    "               ]:\n",
    "        if key in movie:\n",
    "            alt_titles[key] = movie[key]\n",
    "            movie.pop(key)\n",
    "    if len(alt_titles) > 0:\n",
    "        movie['alt_titles'] = alt_titles\n",
    "    \n",
    "    # merge column names\n",
    "    def change_column_name(old_name, new_name):\n",
    "        if old_name in movie:\n",
    "            movie[new_name] = movie.pop(old_name)\n",
    "\n",
    "    # following two columns of the 193 could be joined perhaps into a column called 'Narrator(s)'\n",
    "    # but leaving two separate columns for now ...\n",
    "    #  'Narrated by',\n",
    "    #  'Voices of',\n",
    "    #\n",
    "    # Determine new names\n",
    "    # two comment lines below concern column-new-name tally totals\n",
    "    #  19(9)[5]{2} : to be changed(no change needed)[already new/keep as is]{to remove/combine later?}\n",
    "    #   : red text(denoted as \"already default\")[all lowercase name]{left #comment, no notation}\n",
    "    change_column_name( 'Adaptation by', 'Writer(s)' )\n",
    "    change_column_name( 'Animation by', 'Animator(s)' )\n",
    "#    change_column_name( 'Composer(s)', '?name')              #already default\n",
    "#    change_column_name( 'Country', '?name')                  #already default\n",
    "    change_column_name( 'Country of origin', 'Country' )\n",
    "    change_column_name( 'Directed by', 'Director' )\n",
    "#    change_column_name( 'Director', '?name')                 #already default\n",
    "\n",
    "    change_column_name( 'Distributed by', 'Distributor' )\n",
    "#     change_column_name( 'Distributed by', 'Distributor(s)' )  # use default in line above instead\n",
    "#     change_column_name( 'Distributor', 'Distributor(s)' )  # make default instead of changing\n",
    "\n",
    "    change_column_name( 'Edited by', 'Editor(s)' )\n",
    "#    change_column_name( 'Editor(s)', '?name')                #already default\n",
    "    change_column_name( 'Length', 'Running time' )\n",
    "    change_column_name( 'Music by', 'Composer(s)' )\n",
    "#    change_column_name( 'Narrated by', 'Narrator(s)' )\n",
    "    change_column_name( 'Original release', 'Release date' )\n",
    "    change_column_name( 'Produced by', 'Producer(s)' )\n",
    "    change_column_name( 'Producer', 'Producer(s)' )\n",
    "#    change_column_name( 'Producer(s)', '?name')              #already default\n",
    "#    change_column_name( 'Production company(s)', '?name')    #already default\n",
    "    change_column_name( 'Productioncompanies ', 'Production company(s)' )\n",
    "    change_column_name( 'Productioncompany ', 'Production company(s)' )\n",
    "#    change_column_name( 'Release date', '?name')             #already default\n",
    "    change_column_name( 'Released', 'Release date' )\n",
    "#    change_column_name( 'Running time', '?name')             #already default\n",
    "    change_column_name( 'Screen story by', 'Writer(s)' )\n",
    "    change_column_name( 'Screenplay by', 'Writer(s)' )\n",
    "    change_column_name( 'Story by', 'Writer(s)' )\n",
    "    change_column_name( 'Theme music composer', 'Composer(s)' )\n",
    "#    change_column_name( 'Voices of', 'Narrator(s)' )\n",
    "    change_column_name( 'Written by', 'Writer(s)' )\n",
    "\n",
    "    return movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Add the function that takes in three arguments;\n",
    "# Wikipedia data, Kaggle metadata, and MovieLens rating data (from Kaggle)\n",
    "\n",
    "#def extract_transform_load():  # function_name():\n",
    "def extract_transform_load(wiki_file, kaggle_file, ratings_file):\n",
    "    # Read in the kaggle metadata and MovieLens ratings CSV files as Pandas DataFrames.\n",
    "    kaggle_metadata = pd.read_csv(kaggle_file, low_memory=False)\n",
    "    ratings = pd.read_csv(ratings_file)\n",
    "\n",
    "    # Open and read the Wikipedia data JSON file.\n",
    "    with open(wiki_file, mode='r') as file:\n",
    "        wiki_movies_raw = json.load(file)\n",
    "        \n",
    "    # D2-3. Write a list comprehension to filter out TV shows.\n",
    "    #   # wiki_movies = [ movie for movie in wiki_movies_raw\n",
    "    #   #                 if 'No. of episodes' not in movie ]\n",
    "\n",
    "    #   # wiki_movies = [ movie for movie in wiki_movies_raw\n",
    "    #   #                 if 'No. of episodes' not in movie\n",
    "    #   #                 and ('Director' in movie or 'Directed by' in movie)\n",
    "    #   #                 and 'imdb_link' in movie\n",
    "    #   #               ]\n",
    "    wiki_movies = [ movie for movie in wiki_movies_raw\n",
    "                    if\n",
    "                    ('Director' in movie or 'Directed by' in movie)\n",
    "                    and 'imdb_link' in movie \\\n",
    "                    and 'No. of episodes' not in movie\n",
    "                  ]\n",
    "\n",
    "    # D2-4. Write a list comprehension to iterate through the cleaned wiki movies list\n",
    "    # and call the clean_movie function on each movie.\n",
    "    clean_movies = [clean_movie(movie) for movie in wiki_movies]\n",
    "\n",
    "    # D2-5. Read in the cleaned movies list from D2-4 as a DataFrame.\n",
    "    # wiki_movies_df = pd.DataFrame(wiki_movies_raw)\n",
    "    wiki_movies_df = pd.DataFrame(clean_movies)\n",
    "\n",
    "    #   print(f\"len (raw):{len(wiki_movies_raw)}, len (pared):{len(clean_movies)};\\nDataFrame (clean):\\\n",
    "    #       \\n    len ... {len(wiki_movies_df)}\\n    columns ... {len(wiki_movies_df.columns)}\")\n",
    "    #   # print(len(wiki_movies_df.columns))\n",
    "    #   print(wiki_movies_df.columns.to_list())\n",
    "    \n",
    "    # D2-6. Write a try-except block to catch errors while extracting the IMDb ID using a regular expression string and\n",
    "    #  dropping any imdb_id duplicates. If there is an error, capture and print the exception.\n",
    "    try:\n",
    "        # wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(\n",
    "        #                     r'(tt\\d{7})')\n",
    "\n",
    "        # wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(\n",
    "        #         r'(tt\\d{7})')[0].drop_duplicates(subset=['imdb_id'], keep=False)\n",
    "\n",
    "        # imdb_id = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')\n",
    "\n",
    "        # wiki_movies_df['imdb_id'] = imdb_id[0].drop_duplicates(keep=False)\n",
    "\n",
    "        # wiki_movies_df['imdb_id'] = (wiki_movies_df['imdb_link'].str.extract(\n",
    "        #     r'(tt\\d{7})')).drop_duplicates(keep=False)       \n",
    "\n",
    "        wiki_movies_df['imdb_id'] = wiki_movies_df['imdb_link'].str.extract(r'(tt\\d{7})')       \n",
    "        wiki_movies_df.drop_duplicates(subset=['imdb_id'], inplace=True)\n",
    "        # wiki_movies_df.drop_duplicates(subset=['imdb_id'], keep=False, inplace=True)\n",
    "                \n",
    "        #code using lambda function modified from Shift-Tab info. for .loc property\n",
    "        #has_duplicate = len(\n",
    "        #    wiki_movies_df.loc[lambda df: df['imdb_id'] == string_check]) > 1\n",
    "        \n",
    "        #if has_duplicate:\n",
    "        #    print(f\"already existing 'imdb_id' = '{string_check}', ... skipping.\")\n",
    "        #else:\n",
    "        #    wiki_movies_df['imdb_id'] = string_check       \n",
    "    except AttributeError:\n",
    "        print(f\"An error (AttributeError) occurred.\")\n",
    "    except KeyError: \n",
    "        print(f\"An error (KeyError) occurred.\")\n",
    "    except SyntaxError:\n",
    "        print(\"An error (SyntaxError) occurred.\")\n",
    "    except TypeError:\n",
    "        print(\"An error (TypeError) occurred.\")\n",
    "    # except ValueError:\n",
    "    #     print(\"A ValueError occurred.\")\n",
    "    \n",
    "    #  D2-7. Write a list comprehension to keep the columns that don't have null values from the wiki_movies_df DataFrame.\n",
    "    # wiki_columns_to_keep = [column for column in wiki_movies_df.columns\\\n",
    "    #       if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "\n",
    "    # wiki_columns_to_keep =\\\n",
    "    #     [column for column in wiki_movies_df.columns\\\n",
    "    #         if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df)]\n",
    "\n",
    "    # keep columns that are 10% or more non-null values (less than 90% is null)\n",
    "    wiki_columns_to_keep = [column for column in wiki_movies_df.columns\\\n",
    "          if wiki_movies_df[column].isnull().sum() < len(wiki_movies_df) * 0.9]\n",
    "\n",
    "    # print(f'{wiki_movies_df[wiki_columns_to_keep].isnull().sum()}')\n",
    "    wiki_movies_df = wiki_movies_df[wiki_columns_to_keep]\n",
    "    \n",
    "    # D2-8. Create a variable that will hold the non-null values from the “Box office” column.\n",
    "    #has_box_office = (wiki_movies_df['Box office'].isnull() == False)\n",
    "    box_office = wiki_movies_df['Box office'].dropna()\n",
    "    \n",
    "    # D2-9. Convert the box office data created in D2-8 to string values using the lambda and join functions.\n",
    "    box_office = box_office.apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "    # D2-10. Write a regular expression to match the six elements of \"form_one\" of the box office data.\n",
    "    #   # \"Create the First Form ['$123.4 million' (or billion) -- Module 8.3.10]\n",
    "    #   # For the first form (f1 comments below), our pattern match string will include six elements\n",
    "    #   # in the following order:\n",
    "    #   #\n",
    "    #f1 # f1_1. A dollar sign\n",
    "    #f1 # f1_2. An arbitrary (but non-zero) number of digits\n",
    "    #f1 # f1_3. An optional decimal point\n",
    "    #f1 # f1_4. An arbitrary (but possibly zero) number of more digits\n",
    "    #f1 # f1_5. A space (maybe more than one)\n",
    "    #f1 # f1_6. The word 'million' or 'billion'\"\n",
    "    \n",
    "    #form_one = r'\\$\\d+\\.?\\d*\\s*[mb]ill?i?on'\n",
    "    form_one = r'\\$\\d+\\.?\\d*\\s*[mb]illion'\n",
    "\n",
    "    # D2-11. Write a regular expression to match the three elements of \"form_two\" of the box office data.\n",
    "    #   # \"Create the Second Form ['$123,456,789' -- Module 8.3.10]\n",
    "    #   # Next ... the numbers of our second form (f2 comments below) ... pattern match string will\n",
    "    #   # include the following (three) elements:\n",
    "    #   #\n",
    "    #f2 # f2_1. A dollar sign\n",
    "    #f2 # f2_2. A group of one to three digits\n",
    "    #f2 # f2_3. At least one group starting with a comma and followed by exactly three digits    \n",
    "    \n",
    "    form_two = r'\\$\\d{1,3}(?:,\\d{3})+'\n",
    "\n",
    "    # D2-12. Add the parse_dollars function.\n",
    "    def parse_dollars(s):\n",
    "        # if s is not a string, return NaN\n",
    "        if type(s) != str:\n",
    "            return np.nan\n",
    "\n",
    "        # if input is of the form $###.# million\n",
    "        #if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*mill?i?on', s, flags=re.I):\n",
    "        if re.match(r'\\$\\s*\\d+\\.?\\d*\\s*million', s, flags=re.I):\n",
    "\n",
    "            # remove dollar sign and \" million\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]', '', s)\n",
    "\n",
    "            # convert to float and multiply by a million\n",
    "            value = float(s) * 10**6\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # if input is of the form $###.# billion\n",
    "        #elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*bill?i?on', s, flags=re.I):\n",
    "        elif re.match(r'\\$\\s*\\d+\\.?\\d*\\s*billion', s, flags=re.I):\n",
    "\n",
    "            # remove dollar sign and \" billion\"\n",
    "            s = re.sub('\\$|\\s|[a-zA-Z]', '', s)\n",
    "\n",
    "            # convert to float and multiply by a billion\n",
    "            value = float(s) * 10**9\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # if input is of the form $###,###,###\n",
    "        elif re.match(r'\\$\\s*\\d{1,3}(?:[,\\.]\\d{3})+(?!\\s[mb]illion)', s, flags=re.I):\n",
    "    \n",
    "            # remove dollar sign and commas\n",
    "            s = re.sub('\\$|,', '', s)\n",
    "\n",
    "            # convert to float\n",
    "            value = float(s)\n",
    "\n",
    "            # return value\n",
    "            return value\n",
    "\n",
    "        # otherwise, return NaN\n",
    "        else:\n",
    "            return np.nan\n",
    "    \n",
    "    # D2-13. Clean the box office column in the wiki_movies_df DataFrame.\n",
    "    #wiki_movies_df['Box office'] = \\\n",
    "    wiki_movies_df['box_office'] = \\\n",
    "              box_office.str.extract(f'({form_one}|{form_two})',\n",
    "                         flags=re.I)[0].apply(parse_dollars)\n",
    "\n",
    "    # Drop the newly converted original (now no longer needed) Box Office column\n",
    "    wiki_movies_df.drop('Box office', axis=1, inplace=True)\n",
    "    \n",
    "    # D2-14. Clean the budget column in the wiki_movies_df DataFrame.\n",
    "    budget = wiki_movies_df['Budget'].dropna()\n",
    "    \n",
    "    #wiki_movies_df['Budget'] = \\\n",
    "    wiki_movies_df['budget'] = \\\n",
    "              budget.str.extract(f'({form_one}|{form_two})',\n",
    "                           flags=re.I)[0].apply(parse_dollars)\n",
    "\n",
    "#     # Drop the newly converted original (now no longer needed) Budget column\n",
    "#     wiki_movies_df.drop('Budget', axis=1, inplace=True)\n",
    "\n",
    "    # D2-15. Clean the release date column in the wiki_movies_df DataFrame.\n",
    "    # \"The (four) forms we'll be parsing are:\"\n",
    "    #  -p1} Full month name, one- to two-digit day, four-digit year\n",
    "    #      (i.e., January 1, 2000)\n",
    "    #  -p2} Four-digit year, two-digit month, two-digit day, with\n",
    "    #      any separator (i.e., 2000-01-01)\n",
    "    #  -p3} Full month name, four-digit year (i.e., January 2000)\n",
    "    #  -p4} Four-digit year\n",
    "    #\n",
    "    date_form_one = \\\n",
    "        r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s[123]?\\d,\\s\\d{4}'\n",
    "    date_form_two = r'\\d{4}.[01]\\d.[0123]\\d'\n",
    "    date_form_three = \\\n",
    "        r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}'\n",
    "    date_form_four = r'\\d{4}'    \n",
    "\n",
    "    # parse the dates with built-in Pandas method\n",
    "    # ..First, make a variable that holds the non-null values of\n",
    "    # Release date in the DataFrame, converting lists to strings:\"\n",
    "    release_date = \\\n",
    "        wiki_movies_df['Release date'].dropna().apply(lambda x: ' '.join(x) if type(x) == list else x)\n",
    "\n",
    "# commenting-out code line below and changing to code line below it so that KeyError\n",
    "# from running lines 337-338 of this cell stops giving KeyError\n",
    "#     wiki_movies_df['Release date'] = pd.to_datetime(\n",
    "    wiki_movies_df['release_date'] = pd.to_datetime(\n",
    "        release_date.str.extract(\n",
    "            f'({date_form_one}|{date_form_two}|{date_form_three}|{date_form_four})')[0],\n",
    "            infer_datetime_format=True)\n",
    "    \n",
    "    # D2-16. Clean the running time column in the wiki_movies_df DataFrame.\n",
    "    # Check for data and parse\n",
    "    running_time = wiki_movies_df['Running time'].dropna().apply(\n",
    "            lambda x: ' '.join(x) if type(x) == list else x)\n",
    "    \n",
    "    # Extract the digits, allowing for alternate patterns\n",
    "    running_time_extract = running_time.str.extract(\n",
    "            r'(\\d+)\\s*ho?u?r?s?\\s*(\\d*)|(\\d+)\\s*m')\n",
    "    \n",
    "    # Convert strings to numeric; coercing the errors to turn any empty\n",
    "    # strings into Not a Number (NaN), then using `fillna()` to change\n",
    "    # all the NaNs to zeros.\"\n",
    "    running_time_extract = running_time_extract.apply(\n",
    "            lambda col: pd.to_numeric(col, errors='coerce')).fillna(0)\n",
    "\n",
    "    # Convert the capture groups to minutes ([0][1] are hours and minutes,\n",
    "    # respectively; capture group [2] is strictly minutes)\n",
    "    wiki_movies_df['running_time'] = running_time_extract.\\\n",
    "        apply(lambda row: row[0]*60 + row[1] if row[2] == 0 else row[2], axis=1)\n",
    "    \n",
    "    # Drop the now converted original `Running time` column from the dataset:\n",
    "    wiki_movies_df.drop('Running time', axis=1, inplace=True)\n",
    "    \n",
    "    # ---Code in the cell below here up to return statement is for cleaning Kaggle metadata---\n",
    "    # change comment immediately above to one immediately below...\n",
    "    # ---Code in the cell below here up to '===' sign lines is for cleaning Kaggle metadata---\n",
    "    #\n",
    "    # As specified in Deliverable 3 for the Module 8 Challenge text,\n",
    "    # in this section of the notebook, will be using \"knowledge of Python, Pandas, the ETL\n",
    "    # process, and code refactoring (to) extract and transform the Kaggle metadata and\n",
    "    # MovieLens rating data, then convert the transformed data into separate DataFrames.\n",
    "    # (will then) merge the Kaggle metadata DataFrame with the Wikipedia movies DataFrame to\n",
    "    # create the `movies_df` DataFrame. Finally, (will) merge the MovieLens rating data\n",
    "    # DataFrame with the `movies_df` DataFrame to create the `movies_with_ratings_df`.\"\n",
    "        \n",
    "    # As inspected, six columns need to converted from 'object' data type as follows\n",
    "    # (in the kaggle_metadata dataframe): \n",
    "    # .  id           -->  'numeric'\n",
    "    # .  popularity   -->  'numeric'\n",
    "    # .  release_date -->  'datetime'\n",
    "    # .  adult        -->  'Boolean'\n",
    "    # .  video        -->  'Boolean'\n",
    "    # .  budget       -->  'numeric'\n",
    "\n",
    "    # # Were to use following code line to remove bad data\n",
    "    # # (e.g., text data in Boolean column), but will use the uncommented\n",
    "    # # code line below this one instead (as will be removing--dropping--\n",
    "    # # the 'adult' column).\n",
    "    # kaggle_metadata[~kaggle_metadata['adult'].isin(['True','False'])]\n",
    "    #\n",
    "    # \"The following code will keep rows where the adult column is\n",
    "    # `False`, and then drop the adult column.\" ...\n",
    "    kaggle_metadata = kaggle_metadata[kaggle_metadata['adult'] == 'False'].drop(\n",
    "                                  'adult',axis='columns')\n",
    "    \n",
    "    # convert 'video' values to Boolean, assign back to column of DataFrame:\n",
    "    kaggle_metadata['video'] = kaggle_metadata['video'] == 'True'\n",
    "    \n",
    "    # \"For the numeric columns, we can just use the `to_numeric()`\n",
    "    # method from Pandas. We'll make sure the `errors=` argument\n",
    "    # is set to `raise`, so we'll know if there's any data that\n",
    "    # can't be converted to numbers.\" --commenting from Mod. 8.3.12\n",
    "    kaggle_metadata['budget'] = kaggle_metadata['budget'].astype(int)\n",
    "\n",
    "    kaggle_metadata['id'] = pd.to_numeric(\n",
    "                            kaggle_metadata['id'], errors='raise')\n",
    "\n",
    "    kaggle_metadata['popularity'] = pd.to_numeric(\n",
    "                                    kaggle_metadata['popularity'], errors='raise')\n",
    "    \n",
    "    # (The above three lines of) \"code above runs without errors,\n",
    "    # so everything converted fine.\" --commenting from Mod. 8.3.12\n",
    "    #\n",
    "    # \"Since `release_date` is in a standard format, `to_datetime()`\n",
    "    # will convert it without any fuss.\" --commenting from Mod. 8.3.12\n",
    "    kaggle_metadata['release_date'] = pd.to_datetime(kaggle_metadata['release_date'])\n",
    "\n",
    "    # === Code in the cell below here, continuing down to \"+++\" sign lines, is to merge ===\n",
    "    # === as specified in comments below, the `wiki_movies_df` and `kaggle_metadata` ===\n",
    "    # === === === === === === === === === DataFrames === === === === === === === === ===\n",
    "\n",
    "    # merge the `wiki_movies_df` and `kaggle_metadata` DataFrames, then name the new\n",
    "    # DataFrame, `movies_df` ...\n",
    "    # (note: using Pandas.merge --will assign to a new DataFrame, specifying left and\n",
    "    # right objects to be joined database-style; as opposed to Pandas.DataFrame.merge\n",
    "    # --where DataFrame is left object and right object is passed as function argument\n",
    "    # to be database-style joined to DataFrame) --see details in 'API reference' at\n",
    "    # pandas.pydata.org website documentation\n",
    "    movies_df = pd.merge(wiki_movies_df, kaggle_metadata, on='imdb_id',\\\n",
    "                         suffixes=['_wiki','_kaggle'])\n",
    "    \n",
    "    # note: after the join, the data still needs to be \"cleaned up a bit, especially where\n",
    "    # Kaggle and Wikipedia data overlap -- redundant columns\" -- Module 8.4.1\n",
    "\n",
    "    # ***Below*** this next code line, will be checking seven cases of modifications to be\n",
    "    # made to `movies_df` DataFrame\n",
    "    # but for this next code line, will be dropping a row with garbled data from Module 8.4.1\n",
    "    # (This title was row index 3607; in the module found with following code--commented-out)...\n",
    "    # (where *\"The Holiday\"* got somehow merged with *\"From Here to Eternity\"*)\n",
    "    # movies_df[(movies_df['release_date_wiki'] > '1996-01-01') &\\\n",
    "    #          (movies_df['release_date_kaggle'] < '1965-01-01')].index\n",
    "    #\n",
    "    # try:\n",
    "    #     input(f'{movies_df.columns.to_list()}')\n",
    "    #     movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & \\\n",
    "    #                                     (movies_df['release_date_kaggle'] < '1965-01-01')].index\n",
    "    # except KeyError as err:\n",
    "    #     print(err)\n",
    "\n",
    "    # print(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') &\\\n",
    "    #               (movies_df['release_date_kaggle'] < '1965-01-01')].index)\n",
    "    # code to drop that row is...\n",
    "    # movies_df = movies_df.drop(movies_df[(movies_df['release_date_wiki'] > '1996-01-01') & \\\n",
    "    #                                     (movies_df['release_date_kaggle'] < '1965-01-01')].index)    \n",
    "    \n",
    "    # summary table is below of resolution to overlapping/redundant columns...\n",
    "    # (determined by review of scatter plots -- except for datetime which used\n",
    "    #  '.'-style line chart plot)\n",
    "# Mod  Wikipedia column name  Kaggle column name     Resolution description\n",
    "# ---  ---------------------  ---------------------  --------------------------------\n",
    "#  A   title_wiki             title_kaggle           Drop Wikipedia.\n",
    "#  B   running_time           runtime                Keep Kaggle; fill-in zeros with Wikipedia data.\n",
    "#  C   budget_wiki            budget_kaggle           \"     \"        \"      \"    \"      \"       \"\n",
    "#  D   box_office             revenue                 \"     \"        \"      \"    \"      \"       \"\n",
    "#  E   release_date_wiki      release_date_kaggle    Drop Wikipedia.\n",
    "#  F   Language               original_language       \"       \"\n",
    "#  G   Production company(s)  production_companies    \"       \"\n",
    "\n",
    "    # Modifications 'A', 'E', 'F', and 'G'.\n",
    "    movies_df.drop(columns=['title_wiki', 'release_date_wiki', 'Language',\\\n",
    "                            'Production company(s)'], inplace=True)\n",
    "    \n",
    "    # for expediency (as instructed), define function below to perform remaining modifications\n",
    "    def fill_missing_kaggle_data(df, kaggle_column, wiki_column):\n",
    "        df[kaggle_column] = df.apply(\n",
    "            lambda row: row[wiki_column] if row[kaggle_column] == 0\n",
    "                        else row[kaggle_column], axis=1)\n",
    "        df.drop(columns=wiki_column, inplace=True)\n",
    "    \n",
    "    # Now, can run the function for the three remaining column modifications ('B', 'C', and 'D')\n",
    "    fill_missing_kaggle_data(movies_df, 'runtime', 'running_time')\n",
    "    fill_missing_kaggle_data(movies_df, 'budget_kaggle', 'budget_wiki')\n",
    "    fill_missing_kaggle_data(movies_df, 'revenue', 'box_office')\n",
    "    \n",
    "    # for loop for checking for and removing if any columns with only one value,\n",
    "    # remembering that for `value_counts()` to work, must convert lists to tuples...\n",
    "    for col in movies_df.columns:\n",
    "        lists_to_tuples = lambda x: tuple(x) if type(x) == list else x\n",
    "        value_counts = movies_df[col].apply(lists_to_tuples).value_counts(dropna=False)\n",
    "        num_values = len(value_counts)\n",
    "        if num_values == 1:\n",
    "            movies_df.drop(col, axis=1, inplace=True)\n",
    "            # print(f\"movies_df['{col}'] uninformative (all same value of '{movies_df[col][0]}');...dropping.\")\n",
    "            # response = input(\"Confirm drop column? '[y]/n'\")\n",
    "            # # print(type(response))            \n",
    "            # if (len(response) == 0) | (response != 'n'):\n",
    "            #     try:\n",
    "            #         movies_df.drop(col, axis=1, inplace=True)\n",
    "            #     # # response = input(\"Confirm drop column? '[y]/n'\")\n",
    "            #     # # if (str(response) == \"\") or (str(response) != 'n'):\n",
    "            #     # if str(input(\"Confirm drop column? '[y]/n'\")) != 'n':\n",
    "            #     #     movies_df.drop(col, axis=1, inplace=True)\n",
    "            #     # else:\n",
    "            #     #     print(f\"movies_df['{col}'] column NOT dropped.\")\n",
    "            #     except KeyError:\n",
    "            #         print(\"KeyError occurred.\")\n",
    "\n",
    "    # \"reorder ... columns roughly in groups (easier to read)\" -- e.g., like this:\n",
    "    # r1. Identifying information (IDs, titles, URLs, etc.)                         \n",
    "    # r2. Quantitative facts (runtime, budget, revenue, etc.)\n",
    "    # r3. Qualitative facts (genres, languages, country, etc.)\n",
    "    # r4. Business data (production conmpanies, distributors, etc.)\n",
    "    # r5. People (producers, director, cast, writers, etc.)\n",
    "                         \n",
    "    # prior to rename of columns, use `.loc` to *reorder* the columns (i.e., ***instead of***\n",
    "    # passing list of column names like `movies_df = movies_df[['imdb_id', 'title_kaggle', ...]]`\n",
    "    # to the indexing operator) so as to avoid receiving a SettingWithCopyWarning.\n",
    "    # Module 8.4.1 note: \"Don't panic! (if receive the message) This isn't an error, so your code\n",
    "    # will continue to work, but it is a warning that (the) code may not behave as expect(ed). In\n",
    "    # this case, your code will work fine, but for best practices, use `.loc` instead to avoid\n",
    "    # this warning.\"\n",
    "    movies_df = movies_df.loc[:, ['imdb_id', 'id', 'title_kaggle', 'original_title', 'tagline',\n",
    "                                  'belongs_to_collection', 'url', 'imdb_link', 'runtime',\n",
    "                                  'budget_kaggle', 'revenue', 'release_date_kaggle',\n",
    "                                  'popularity', 'vote_average', 'vote_count', 'genres',\n",
    "                                  'original_language', 'overview', 'spoken_languages',\n",
    "                                  'Country', 'production_companies', 'production_countries',\n",
    "                                  'Distributor', 'Producer(s)', 'Director', 'Starring',\n",
    "                                  'Cinematography', 'Editor(s)', 'Writer(s)', 'Composer(s)',\n",
    "                                  'Based on'\n",
    "                                 ]]\n",
    "    # after reordering with `.loc` as noted in comment (to avoid receiving a\n",
    "    # SettingWithCopyWarning) and coded above, \"rename the columns to be consistent\"\n",
    "    #                                                                  --Module 8.4.1\n",
    "    movies_df.rename({'id':'kaggle_id',\n",
    "                      'title_kaggle':'title',\n",
    "                      'url':'wikipedia_url',\n",
    "                      'budget_kaggle':'budget',\n",
    "                      'release_date_kaggle':'release_date',\n",
    "                      'Country':'country',\n",
    "                      'Distributor':'distributor',\n",
    "                      'Producer(s)':'producers',\n",
    "                      'Director':'director',\n",
    "                      'Starring':'starring',\n",
    "                      'Cinematography':'cinematography',\n",
    "                      'Editor(s)':'editors',\n",
    "                      'Writer(s)':'writers',\n",
    "                      'Composer(s)':'composers',\n",
    "                      'Based on':'based_on'\n",
    "                     }, axis='columns', inplace=True)\n",
    "    \n",
    "\n",
    "    # +++ Code in the cell below here, down to return statement, is to merge as specified +++    \n",
    "    # +++ in comments below, the metadata from the `movies_df` and `ratings` DataFrames into +++\n",
    "    # +++ +++ a new DataFrame `movies_with_ratings_df`, then clean the new DataFrame +++ +++\n",
    "   \n",
    "    # in the Module, specifically in 8.3.12, we reviewed the 'timestamp' column from the ratings\n",
    "    # csv data file. we will see later on in this cell, that do not use this 'timestamp' column\n",
    "    # for our own analysis purposes; however, as will be storing rating data as own table in SQL,\n",
    "    # will (need to) convert that timestamp data to a datetime data type. \"From the MovieLens\n",
    "    # documentation, the timestamp is the number of seconds since midnight of January 1, 1970\n",
    "    # (known as the Unix **epoch**.)\"\n",
    "    ratings['timestamp'] = pd.to_datetime(ratings['timestamp'], unit='s')\n",
    "    \n",
    "    # \"a ... useful summary is (for ratings data file).. to count how many times a movie\n",
    "    # received a given rating. This way, someone who wants to calculate statistics for the\n",
    "    # dataset (has) all the information they need ... easy enough to do. Plus, (can)\n",
    "    # calculate statistics ... without having to work with a dataset containing 26-\n",
    "    # million rows. ..First, ... use a `groupby` on the 'movieID' and 'rating'\n",
    "    # columns and take the count for each group.\" --comments quoted from Mod. 8.4.2\n",
    "    # code looks like following line...(commented out as will be completed lower below)\n",
    "#     rating_counts = ratings.groupby(['movieId','rating'], as_index=False).count()\n",
    "    #\n",
    "    # (then next, and as it turns out arbitrarily -- as \"timestamp\" column has the\n",
    "    # same information; \"so ...could use either one.\")\n",
    "    # \"rename the 'userID' column to 'count.'\" --from Module 8.4.2\n",
    "    # (also commented out below as will be completed below yet again another time)\n",
    "#     rating_counts = ratings.groupby(['movieId','rating'], as_index=False).\\\n",
    "#                         count.rename({'userID':'count'}, axis=1)\n",
    "    #\n",
    "    # now, for a \"magical part\" whereby \"pivot this data so that `movieId` is the\n",
    "    # index, the columns will be all the rating values, and the rows will be the\n",
    "    # counts for each rating value.\" --Module 8.4.2\n",
    "    rating_counts = ratings.groupby(['movieId','rating'], as_index=False).\\\n",
    "                    count().rename({'userId':'count'}, axis=1).\\\n",
    "                    pivot(index='movieId', columns='rating', values='count')\n",
    "    #\n",
    "    # and then so that the \"columns (are) easier to understand ... (rename with a)\n",
    "    # prepend (of) `rating_` to each column with a list comprehension:\" --Module 8.4.2\n",
    "    rating_counts.columns = ['rating_' + str(col) for col in rating_counts.columns]\n",
    "    \n",
    "    # Now we can merge the rating counts into `movies_df` (note use a left merge, since\n",
    "    # we want to keep everything in `movies_df`:) --Module 8.4.2\n",
    "    # (note: using Pandas.merge --will assign to a new DataFrame, specifying left and\n",
    "    # right objects to be joined database-style; as opposed to Pandas.DataFrame.merge\n",
    "    # --where DataFrame is left object and right object is passed as function argument\n",
    "    # to be database-style joined to DataFrame) --see details in 'API reference' at\n",
    "    # pandas.pydata.org website documentation\n",
    "    # perform the merge of the DataFrames\n",
    "    movies_with_ratings_df = pd.merge(movies_df, rating_counts, left_on='kaggle_id',\n",
    "                                     right_index=True, how='left')\n",
    "    #\n",
    "    # Clean the `movies_with_ratings_df` DataFrame by filling in missing values with zeros\n",
    "    movies_with_ratings_df[rating_counts.columns] =\\\n",
    "                         movies_with_ratings_df[rating_counts.columns].fillna(0)\n",
    "    \n",
    "#     return wiki_movies_df, movies_with_ratings_df, movies_df\n",
    "#     return wiki_movies_df, movies_with_ratings_df, movies_df\n",
    "\n",
    "    # Below here in cell, will \"add the code to create the connection to the PostgreSQL database,\n",
    "    # then add the `movies_df` DataFrame to a SQL database.\"\n",
    "\n",
    "    # connection string for local server\n",
    "    db_string = f'postgresql://postgres:{db_password}@127.0.0.1:5432/movie_data'\n",
    "    \n",
    "    # create the database engine\n",
    "    engine = create_engine(db_string)\n",
    "    \n",
    "    # --Import the Movie Data\n",
    "    # \"To save the `movies_df` DataFrame to a SQL table, we only have\n",
    "    # to specify the name of the table and the engine in the `to_sql()`\n",
    "    # method.\" ...\n",
    "    movies_df.to_sql(name='movies', con=engine, if_exists='replace')\n",
    "    \n",
    "    # --Import the Ratings Data\n",
    "    rows_imported = 0\n",
    "\n",
    "    # get the start_time from time.time()\n",
    "    start_time = time.time()\n",
    "\n",
    "    for data in pd.read_csv(ratings_file, chunksize=1000000):\n",
    "        print(f'importing rows {rows_imported} to {rows_imported + len(data)}...', end='')\n",
    "        data.to_sql(name='ratings', con=engine, if_exists='replace')\n",
    "        rows_imported += len(data)\n",
    "\n",
    "        # add elapsed time to final print out\n",
    "        print(f'Done. {time.time() - start_time} total seconds elapsed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Create the path to your file directory and variables for the three files.\n",
    "file_dir = \"../../../DataBootcamp/Mod_8/\"\n",
    "# The Wikipedia data\n",
    "#wiki_file = f'{file_dir}/wikipedia_movies.json'\n",
    "wiki_file = f'{file_dir}/wikipedia-movies.json'\n",
    "# The Kaggle metadata\n",
    "kaggle_file = f'{file_dir}/movies_metadata.csv'\n",
    "# The MovieLens rating data.\n",
    "ratings_file = f'{file_dir}/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing rows 0 to 1000000...Done. 18.011428594589233 total seconds elapsed\n",
      "importing rows 1000000 to 2000000...Done. 35.81978702545166 total seconds elapsed\n",
      "importing rows 2000000 to 3000000...Done. 53.1935031414032 total seconds elapsed\n",
      "importing rows 3000000 to 4000000...Done. 70.92681407928467 total seconds elapsed\n",
      "importing rows 4000000 to 5000000...Done. 88.36711072921753 total seconds elapsed\n",
      "importing rows 5000000 to 6000000...Done. 105.83458495140076 total seconds elapsed\n",
      "importing rows 6000000 to 7000000...Done. 123.32278323173523 total seconds elapsed\n",
      "importing rows 7000000 to 8000000...Done. 141.15830159187317 total seconds elapsed\n",
      "importing rows 8000000 to 9000000...Done. 158.82565808296204 total seconds elapsed\n",
      "importing rows 9000000 to 10000000...Done. 176.2566487789154 total seconds elapsed\n",
      "importing rows 10000000 to 11000000...Done. 193.79438948631287 total seconds elapsed\n",
      "importing rows 11000000 to 12000000...Done. 211.21581554412842 total seconds elapsed\n",
      "importing rows 12000000 to 13000000...Done. 228.89921855926514 total seconds elapsed\n",
      "importing rows 13000000 to 14000000...Done. 246.56813526153564 total seconds elapsed\n",
      "importing rows 14000000 to 15000000...Done. 264.0658977031708 total seconds elapsed\n",
      "importing rows 15000000 to 16000000...Done. 281.45630979537964 total seconds elapsed\n",
      "importing rows 16000000 to 17000000...Done. 299.0703730583191 total seconds elapsed\n",
      "importing rows 17000000 to 18000000...Done. 316.6530396938324 total seconds elapsed\n",
      "importing rows 18000000 to 19000000...Done. 334.489958524704 total seconds elapsed\n",
      "importing rows 19000000 to 20000000...Done. 353.1917541027069 total seconds elapsed\n",
      "importing rows 20000000 to 21000000...Done. 370.7182445526123 total seconds elapsed\n",
      "importing rows 21000000 to 22000000...Done. 388.4403293132782 total seconds elapsed\n",
      "importing rows 22000000 to 23000000...Done. 406.32763266563416 total seconds elapsed\n",
      "importing rows 23000000 to 24000000...Done. 424.3673803806305 total seconds elapsed\n",
      "importing rows 24000000 to 25000000...Done. 442.70200991630554 total seconds elapsed\n",
      "importing rows 25000000 to 26000000...Done. 460.22430086135864 total seconds elapsed\n",
      "importing rows 26000000 to 26024289...Done. 460.66028356552124 total seconds elapsed\n"
     ]
    }
   ],
   "source": [
    "# 11. Set the three variables equal to the function created in D1.\n",
    "# wiki_file, kaggle_file, ratings_file = extract_transform_load()\n",
    "extract_transform_load(wiki_file, kaggle_file, ratings_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratings_file.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 12. Set the DataFrames from the return statement equal to the file names in Step 11. \n",
    "# wiki_movies_df = wiki_file\n",
    "# movies_with_ratings_df = kaggle_file\n",
    "# movies_df = ratings_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 13. Check the wiki_movies_df DataFrame. \n",
    "# wiki_movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 14. Check the movies_with_ratings_df DataFrame.\n",
    "# movies_with_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 15. Check the movies_df DataFrame. \n",
    "# movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
